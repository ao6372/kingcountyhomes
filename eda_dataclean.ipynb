{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "import urllib.request\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import concat, col, split\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .master(\"local[4]\") \\\n",
    "            .appName(\"case study\") \\\n",
    "            .getOrCreate()\n",
    "            \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_real_prop_account(path='rawdata/real_property_account.csv'):\n",
    "    #extracts zipcodes \n",
    "    df=spark.read.csv(path, header=True)\n",
    "    \n",
    "    df.registerTempTable(\"prop_account\")\n",
    "    query=\"SELECT * from prop_account WHERE CityState LIKE '%WA'\"\n",
    "    df=spark.sql(query)\n",
    "    \n",
    "    colkey=df.select('ZipCode', concat(col(\"Major\"), col(\"Minor\")))\n",
    "    \n",
    "    #make pin column to join df together and match with zipcode\n",
    "    colkey1=colkey.withColumnRenamed(existing='concat(Major, Minor)', new='pin')\n",
    "    colkey2=colkey1.withColumn('Zip',rtrim(colkey1['ZipCode']))\n",
    "    colkey3=colkey2.select('Zip','pin')\n",
    "    finaldf=colkey3.withColumn('Zip', colkey3.Zip.cast('int'))\n",
    "    return finaldf\n",
    "\n",
    "def clean_res_building(path='rawdata/res_building.csv'):\n",
    "    import pyspark.sql.functions as F\n",
    "    df1=spark.read.csv(path, header=True)\n",
    "    colkey=df1.withColumn('Zip', F.rtrim(df1['ZipCode']))\n",
    "    \n",
    "    #make pin column to join df together and match with zipcode\n",
    "    colkey1=colkey.withColumn('pin',concat(col(\"Major\"), col(\"Minor\")))\n",
    "    dffinal=colkey1.select(['pin','Zip','NbrLivingUnits','SqFtTotLiving','YrBuilt','Bedrooms', 'BathFullCount'])\n",
    "    dffinal1=dffinal.withColumn(\"NbrLivingUnits_n\", dffinal.NbrLivingUnits.cast(\"int\"))\n",
    "    dffinal2=dffinal1.withColumn(\"SqFtTotLiving\", dffinal.SqFtTotLiving.cast(\"int\"))\n",
    "    dffinal3=dffinal2.withColumn(\"YrBuilt\", dffinal.YrBuilt.cast(\"int\"))\n",
    "    dffinal4=dffinal3.withColumn(\"Bedrooms\", dffinal.Bedrooms.cast(\"int\"))\n",
    "    dffinal5=dffinal4.withColumn(\"BathFullCount\", dffinal.BathFullCount.cast(\"int\"))\n",
    "    return dffinal5\n",
    "\n",
    "def clean_sales_data(path='rawdata/real_property_sales.csv'):\n",
    "    df = spark.read.csv(path,\n",
    "                             header=True,\n",
    "                             quote='\"',\n",
    "                             sep=\",\",\n",
    "                             inferSchema=True)\n",
    "    \n",
    "    df1=df.withColumn(\"pin\", concat(df.Major, df.Minor))\n",
    "    #df2=df1.withColumn('Month', split(df.DocumentDate, '/').alias('date').getItem(0).cast(\"int\"))\n",
    "    #df2=df2.withColumn('Day', split(df.DocumentDate, '/').alias('date').getItem(1).cast(\"int\"))\n",
    "    df2=df1.withColumn('Year', split(df.DocumentDate, '/').alias('date').getItem(2).cast(\"int\"))\n",
    "\n",
    "    \n",
    "    df3=df2.select(['pin','Year','SalePrice'])\n",
    "    df4=df3.filter((df3.Year>=2005) & (df3.Year<=2015))\n",
    "    df5=df4.filter(df4.SalePrice>=20000)\n",
    "\n",
    "    return df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=clean_res_building()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------+-------------+-------+--------+-------------+----------------+\n",
      "|       pin|  Zip|NbrLivingUnits|SqFtTotLiving|YrBuilt|Bedrooms|BathFullCount|NbrLivingUnits_n|\n",
      "+----------+-----+--------------+-------------+-------+--------+-------------+----------------+\n",
      "|0421049114|98003|             1|          910|   1955|       3|            1|               1|\n",
      "|0421049129|98003|             1|         1420|   1958|       4|            1|               1|\n",
      "|0421049137|98003|             1|         1010|   1959|       3|            1|               1|\n",
      "+----------+-----+--------------+-------------+-------+--------+-------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_df=clean_real_prop_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|  Zip|       pin|\n",
      "+-----+----------+\n",
      "|98002|0000800027|\n",
      "|98071|0000800047|\n",
      "|98002|0001000035|\n",
      "+-----+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rp_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df=res_df.join(rp_df, on='pin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------+-------------+-------+--------+-------------+----------------+-----+\n",
      "|       pin|  Zip|NbrLivingUnits|SqFtTotLiving|YrBuilt|Bedrooms|BathFullCount|NbrLivingUnits_n|  Zip|\n",
      "+----------+-----+--------------+-------------+-------+--------+-------------+----------------+-----+\n",
      "|0006200017|98032|             1|         1340|   1945|       3|            1|               1|98032|\n",
      "|0006200017|98032|             1|         1340|   1945|       3|            1|               1|98032|\n",
      "|0006600059|98032|             1|          840|   1940|       2|            1|               1|98032|\n",
      "+----------+-----+--------------+-------------+-------+--------+-------------+----------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feat_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[pin: string, Zip: string, NbrLivingUnits: string, SqFtTotLiving: int, YrBuilt: int, Bedrooms: int, BathFullCount: int, NbrLivingUnits_n: int, Zip: int]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_df=clean_sales_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+---------+\n",
      "|       pin|Year|SalePrice|\n",
      "+----------+----+---------+\n",
      "|1388600110|2014|   245000|\n",
      "|3303951610|2012|   335000|\n",
      "|6385800110|2015|   190000|\n",
      "+----------+----+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
